{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b441ac05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_disabled_torch_function_impl' from 'torch._C' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[0;32m      4\u001b[0m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[0;32m      5\u001b[0m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Identity, Linear, Bilinear, LazyLinear\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1d, Conv2d, Conv3d, \\\n\u001b[0;32m      4\u001b[0m     ConvTranspose1d, ConvTranspose2d, ConvTranspose3d, \\\n\u001b[0;32m      5\u001b[0m     LazyConv1d, LazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d, LazyConvTranspose3d\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mweakref\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parameter\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor, device, dtype\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\parameter.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disabled_torch_function_impl\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Metaclass to combine _TensorMeta and the instance check override for Parameter.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_disabled_torch_function_impl' from 'torch._C' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transform\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "torch.utils.data.Dataset\n",
    "import torchvision\n",
    "import pathlib\n",
    "from torch.optim import Adam\n",
    "import glob\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d5a8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f66cc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc9af83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650 Ti'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1313af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='C:/Users/paltu/anaconda jp/eye/train'\n",
    "pred_path='C:/Users/paltu/anaconda jp/eye/pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf78f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6fc7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10404_left.jpeg\n",
      "10404_right.jpeg\n",
      "10407_left.jpeg\n",
      "10407_right.jpeg\n",
      "10408_left.jpeg\n"
     ]
    }
   ],
   "source": [
    "# get the path or directory\n",
    "# folder_dir = \"C:/Users/RIJUSHREE/Desktop/Gfg images\"\n",
    "for images in os.listdir(pred_path)[0:5]:\n",
    " \n",
    "    # check if the image ends with png or jpg or jpeg\n",
    "    if (images.endswith(\".png\") or images.endswith(\".jpg\")\\\n",
    "        or images.endswith(\".jpeg\")):\n",
    "        # display\n",
    "        print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd175073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0587bd3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cataract', 'diabetic_retinopathy', 'glaucoma', 'normal']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d944a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict={}\n",
    "\n",
    "name_dict['cataract']=0\n",
    "name_dict['diabetic_retinopathy']=1\n",
    "name_dict['glaucoma']=2\n",
    "name_dict['normal']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c46e1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cataract': 0, 'diabetic_retinopathy': 1, 'glaucoma': 2, 'normal': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3925fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"name_dict.json\",\"w\") as f:\n",
    "    f.write(json.dumps(name_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41cdf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=4):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn2=nn.BatchNorm2d(num_features=20)\n",
    "        self.relu2=nn.ReLU()\n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3=nn.ReLU()\n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75*75*32,out_features=num_classes)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "        output=self.pool(output)\n",
    "        output=self.conv2(output)\n",
    "        output=self.bn2(output)\n",
    "        output=self.relu2(output)\n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "        \n",
    "        \n",
    "        output=output.view(-1,32*75*75)\n",
    "        output=self.fc(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "141bdc82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc): Linear(in_features=180000, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint=torch.load('best_checkpoint4.model')\n",
    "model=ConvNet(num_classes=4)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5d9854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2045f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c58d3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed8b8224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img_path,transformer):\n",
    "    image=Image.open(img_path)\n",
    "    image_tensor=transformer(image).float();\n",
    "    \n",
    "    image_tensor=image_tensor.unsqueeze_(0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor.cuda()\n",
    "    input=Variable(image_tensor)\n",
    "    \n",
    "    output=model(input)\n",
    "    index=output.data.numpy().argmax()\n",
    "    \n",
    "    pred=classes[index]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2c6e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path1=glob.glob(pred_path+'/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd724d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path2=glob.glob(pred_path+'/*.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "645ffec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path3=glob.glob(pred_path+'/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7e1a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict2={}\n",
    "\n",
    "for i in images_path2:\n",
    "    pred_dict2[i[i.rfind('/')+1:]]=prediction(i,transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4db77a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred\\\\10404_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10404_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10407_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10407_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10408_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10408_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10409_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10409_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10752_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10755_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10755_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10758_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10758_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10761_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10761_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10762_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10762_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10763_left.jpeg': 'normal',\n",
       " 'pred\\\\10763_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\1076_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\1076_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10770_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10770_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10772_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10772_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10777_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10777_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10779_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10779_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\1077_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\1077_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10781_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10781_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\10782_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\1084_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\1084_right.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\1092_left.jpeg': 'diabetic_retinopathy',\n",
       " 'pred\\\\1092_right.jpeg': 'diabetic_retinopathy'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4b5e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict3={}\n",
    "\n",
    "for i in images_path3:\n",
    "    pred_dict3[i[i.rfind('/')+1:]]=prediction(i,transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cad792d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred\\\\cataract_039.png': 'glaucoma',\n",
       " 'pred\\\\cataract_040.png': 'cataract',\n",
       " 'pred\\\\cataract_041.png': 'cataract',\n",
       " 'pred\\\\cataract_043.png': 'cataract',\n",
       " 'pred\\\\cataract_044.png': 'glaucoma',\n",
       " 'pred\\\\cataract_045.png': 'cataract'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "727622d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict={}\n",
    "\n",
    "for i in images_path1:\n",
    "    pred_dict[i[i.rfind('/')+1:]]=prediction(i,transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e132331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred\\\\2244_right.jpg': 'cataract',\n",
       " 'pred\\\\2246_left.jpg': 'cataract',\n",
       " 'pred\\\\2246_right.jpg': 'cataract',\n",
       " 'pred\\\\2247_left.jpg': 'cataract',\n",
       " 'pred\\\\2247_right.jpg': 'cataract',\n",
       " 'pred\\\\2248_left.jpg': 'cataract',\n",
       " 'pred\\\\2248_right.jpg': 'cataract',\n",
       " 'pred\\\\2251_right.jpg': 'cataract',\n",
       " 'pred\\\\2384_right.jpg': 'normal',\n",
       " 'pred\\\\2386_left.jpg': 'normal',\n",
       " 'pred\\\\2386_right.jpg': 'normal',\n",
       " 'pred\\\\2388_left.jpg': 'normal',\n",
       " 'pred\\\\2388_right.jpg': 'normal',\n",
       " 'pred\\\\2389_left.jpg': 'normal',\n",
       " 'pred\\\\2389_right.jpg': 'normal',\n",
       " 'pred\\\\2393_left.jpg': 'normal',\n",
       " 'pred\\\\2393_right.jpg': 'normal',\n",
       " 'pred\\\\2394_left.jpg': 'normal',\n",
       " 'pred\\\\2394_right.jpg': 'normal',\n",
       " 'pred\\\\2395_left.jpg': 'normal',\n",
       " 'pred\\\\2659_left.jpg': 'normal',\n",
       " 'pred\\\\2659_right.jpg': 'normal',\n",
       " 'pred\\\\2660_left.jpg': 'normal',\n",
       " 'pred\\\\2660_right.jpg': 'normal',\n",
       " 'pred\\\\2661_left.jpg': 'normal',\n",
       " 'pred\\\\2661_right.jpg': 'normal',\n",
       " 'pred\\\\2662_left.jpg': 'normal',\n",
       " 'pred\\\\2662_right.jpg': 'normal',\n",
       " 'pred\\\\_0_4517448.jpg': 'glaucoma',\n",
       " 'pred\\\\_1_4540560.jpg': 'glaucoma',\n",
       " 'pred\\\\_2_5194189.jpg': 'glaucoma',\n",
       " 'pred\\\\_2_8820241.jpg': 'glaucoma',\n",
       " 'pred\\\\_3_6499308.jpg': 'glaucoma',\n",
       " 'pred\\\\_4_1717111.jpg': 'glaucoma',\n",
       " 'pred\\\\_4_5317326.jpg': 'glaucoma',\n",
       " 'pred\\\\_5_5487582.jpg': 'glaucoma',\n",
       " 'pred\\\\_82_3719382.jpg': 'glaucoma',\n",
       " 'pred\\\\_83_9155730.jpg': 'glaucoma',\n",
       " 'pred\\\\_84_2885250.jpg': 'cataract',\n",
       " 'pred\\\\_85_9846035.jpg': 'normal',\n",
       " 'pred\\\\_86_1386374.jpg': 'normal',\n",
       " 'pred\\\\_87_9110812.jpg': 'normal',\n",
       " 'pred\\\\_88_3424776.jpg': 'glaucoma',\n",
       " 'pred\\\\_88_3707930.jpg': 'glaucoma'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaed6fdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_path1)+len(images_path2)+len(images_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2706e480",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m pred_dict\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mimages_path\u001b[49m:\n\u001b[0;32m      4\u001b[0m     pred_dict[i[i\u001b[38;5;241m.\u001b[39mrfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m):]]\u001b[38;5;241m=\u001b[39mprediction(i,transformer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images_path' is not defined"
     ]
    }
   ],
   "source": [
    "pred_dict={}\n",
    "\n",
    "for i in images_path:\n",
    "    pred_dict[i[i.rfind('/'):]]=prediction(i,transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9998d419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0910e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.20.0-cp310-cp310-win_amd64.whl (736 kB)\n",
      "     -------------------------------------- 736.6/736.6 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting typeguard<3.0.0,>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from tensorflow-addons) (22.0)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n",
      "Obtaining file:///C:/Users/paltu/anaconda%20jp/onnx-tensorflow\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: onnx>=1.10.2 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from onnx-tf==1.10.0) (1.14.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from onnx-tf==1.10.0) (6.0)\n",
      "Requirement already satisfied: tensorflow_addons in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from onnx-tf==1.10.0) (0.20.0)\n",
      "Collecting tensorflow_probability\n",
      "  Downloading tensorflow_probability-0.20.1-py2.py3-none-any.whl (6.9 MB)\n",
      "     ---------------------------------------- 6.9/6.9 MB 50.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (4.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (4.23.2)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from tensorflow_addons->onnx-tf==1.10.0) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from tensorflow_addons->onnx-tf==1.10.0) (22.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from tensorflow_probability->onnx-tf==1.10.0) (1.4.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from tensorflow_probability->onnx-tf==1.10.0) (5.1.1)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp310-cp310-win_amd64.whl (101 kB)\n",
      "     ------------------------------------- 101.3/101.3 kB 38.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from tensorflow_probability->onnx-tf==1.10.0) (1.16.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from tensorflow_probability->onnx-tf==1.10.0) (2.0.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from tensorflow_probability->onnx-tf==1.10.0) (0.4.0)\n",
      "Installing collected packages: dm-tree, tensorflow_probability, onnx-tf\n",
      "  Running setup.py develop for onnx-tf\n",
      "Successfully installed dm-tree-0.1.8 onnx-tf-1.10.0 tensorflow_probability-0.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'onnx-tensorflow'...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install tensorflow-addons\n",
    "!git clone https://github.com/onnx/onnx-tensorflow.git && cd onnx-tensorflow && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ed8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved pytorch model and export it as an onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6767fab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_model\u001b[38;5;241m=\u001b[39m\u001b[43mNet\u001b[49m()\n\u001b[0;32m      2\u001b[0m trained_model\u001b[38;5;241m.\u001b[39mload_state_dict()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Net' is not defined"
     ]
    }
   ],
   "source": [
    "trained_model=Net()\n",
    "trained_model.load_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba7dfb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the class labels for your model\n",
    "classes = ['cataract', 'diabetic_retinopathy', 'glaucoma', 'normal']\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((150,150))\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "# Function to predict the disease\n",
    "def predict_disease(image_path):\n",
    "    # Load your pre-trained model here\n",
    "    # Replace 'model.pth' with the path to your trained model file\n",
    "    model = ConvNet()  # Replace YourModel with your own model class\n",
    "    model.load_state_dict(torch.load('best_checkpoint4.model'))\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image_path)\n",
    "    \n",
    "    # Make the prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Get the predicted class\n",
    "    predicted_class = classes[predicted.item()]\n",
    "    return predicted_class\n",
    "\n",
    "# Function to handle the image selection\n",
    "def select_image():\n",
    "    # Open a file dialog to choose an image file\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    \n",
    "    # Display the selected image in the GUI\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((300, 300))\n",
    "    image = ImageTk.PhotoImage(image)\n",
    "    image_label.configure(image=image)\n",
    "    image_label.image = image\n",
    "    \n",
    "    # Call the predict_disease function and display the predicted class\n",
    "    predicted_class = predict_disease(file_path)\n",
    "    result_label.config(text=\"Predicted Disease: \" + predicted_class)\n",
    "\n",
    "# Create the main Tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"Disease Prediction\")\n",
    "window.geometry(\"400x400\")\n",
    "\n",
    "# Create a button to select an image\n",
    "select_button = tk.Button(window, text=\"Select Image\", command=select_image)\n",
    "select_button.pack(pady=10)\n",
    "\n",
    "# Create a label to display the selected image\n",
    "image_label = tk.Label(window)\n",
    "image_label.pack()\n",
    "\n",
    "# Create a label to display the predicted disease\n",
    "result_label = tk.Label(window, text=\"Predicted Disease: \")\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac1b5b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyinstaller in c:\\users\\paltu\\anaconda3\\lib\\site-packages (5.12.0)\n",
      "Requirement already satisfied: pyinstaller-hooks-contrib>=2021.4 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from pyinstaller) (2023.3)\n",
      "Requirement already satisfied: altgraph in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from pyinstaller) (0.17.3)\n",
      "Requirement already satisfied: pefile>=2022.5.30 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from pyinstaller) (2023.2.7)\n",
      "Requirement already satisfied: setuptools>=42.0.0 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from pyinstaller) (65.6.3)\n",
      "Requirement already satisfied: pywin32-ctypes>=0.2.0 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from pyinstaller) (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for xarray: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\xarray-2022.11.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for transformers: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\transformers-4.24.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for statsmodels: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels-0.13.5.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for seaborn: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\seaborn-0.12.2.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for scikit-learn: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\scikit_learn-1.2.1.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for scikit-image: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\scikit_image-0.19.3.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for pywavelets: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\PyWavelets-1.4.1.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for pandas: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas-1.5.3.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for imbalanced-learn: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\imbalanced_learn-0.10.1.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for hvplot: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\hvplot-0.8.2.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for holoviews: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\holoviews-1.15.4.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for gensim: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\gensim-4.3.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for datashader: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\datashader-0.14.4.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for astropy: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\astropy-5.1.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install pyinstaller\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c78f789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xarray in c:\\users\\paltu\\anaconda3\\lib\\site-packages (2022.11.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas-1.5.3.dist-info\\\\METADATA'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting xarray\n",
      "  Using cached xarray-2023.5.0-py3-none-any.whl (994 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from xarray) (22.0)\n",
      "Requirement already satisfied: pandas>=1.4 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from xarray) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\paltu\\anaconda3\\lib\\site-packages (from xarray) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d550b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pandas 1.5.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No metadata found in c:\\users\\paltu\\anaconda3\\lib\\site-packages\n",
      "ERROR: Cannot uninstall pandas 1.5.3, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps pandas==1.5.3'.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0df3691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\paltu\\anaconda3\\lib\\site-packages (1.5.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\paltu\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas-1.5.3.dist-info\\\\METADATA'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da25ed4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3734642276.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[41], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pyinstaller eyeproject2.ipynb\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pyinstaller eyeproject2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34369f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
